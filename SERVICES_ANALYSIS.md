# ðŸ“Š PhÃ¢n TÃ­ch Chi Tiáº¿t CÃ¡c Services

## Tá»•ng Quan Services Layer

Services layer lÃ  trÃ¡i tim cá»§a há»‡ thá»‘ng, chá»‹u trÃ¡ch nhiá»‡m xá»­ lÃ½:
- **Vector Storage**: LÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m embeddings
- **Event Streaming**: Xá»­ lÃ½ real-time events
- **Background Processing**: Xá»­ lÃ½ báº¥t Ä‘á»“ng bá»™

---

## 1. ðŸ” Vector Store Service (`vector_store.py`)

### 1.1 Tá»•ng Quan
**Má»¥c Ä‘Ã­ch**: Quáº£n lÃ½ vector embeddings trong Redis, há»— trá»£ similarity search

**Pattern**: Singleton Pattern
- Äáº£m báº£o chá»‰ cÃ³ má»™t instance duy nháº¥t
- Tá»‘i Æ°u káº¿t ná»‘i Redis
- Shared state across application

### 1.2 Kiáº¿n TrÃºc

```python
RedisVectorStore (Singleton)
â”œâ”€â”€ Redis Client Connection
â”œâ”€â”€ Vector Index Management (HNSW)
â”œâ”€â”€ Embedding Storage
â””â”€â”€ Similarity Search
```

### 1.3 Chi Tiáº¿t Implementation

#### **1.3.1 Initialization**
```python
def __new__(cls):
    if cls._instance is None:
        cls._instance = super(RedisVectorStore, cls).__new__(cls)
        # Initialize Redis with binary mode for vectors
        cls._instance.redis = redis.Redis(
            decode_responses=False  # Critical for vector bytes
        )
        cls._instance._ensure_vector_index()
```

**Äáº·c Ä‘iá»ƒm**:
- `decode_responses=False`: Quan trá»ng Ä‘á»ƒ xá»­ lÃ½ vector bytes
- Auto-create index náº¿u chÆ°a tá»“n táº¡i
- Thread-safe singleton

#### **1.3.2 Vector Index (HNSW)**
```python
def _ensure_vector_index(self):
    self.redis.execute_command(
        "FT.CREATE", VECTOR_INDEX_NAME,
        "ON", "HASH",
        "PREFIX", 1, "product:embedding:",
        "SCHEMA", "vector", "VECTOR", "HNSW", 6,
        "TYPE", "FLOAT32",
        "DIM", VECTOR_DIMENSION,  # 384
        "DISTANCE_METRIC", "COSINE"
    )
```

**Cáº¥u hÃ¬nh HNSW**:
- **Algorithm**: HNSW (Hierarchical Navigable Small World)
- **M (HNSW parameter)**: 6
- **Dimension**: 384 (tá»« TF-IDF model)
- **Distance Metric**: Cosine similarity
- **Storage**: FLOAT32 (4 bytes per dimension = 1.5KB per vector)

**Redis Structure**:
```
product:embedding:{product_id}
â”œâ”€â”€ vector: [binary FLOAT32 array]
â”œâ”€â”€ category: "electronics"
â”œâ”€â”€ name: "Product Name"
â”œâ”€â”€ price: "99.99"
â””â”€â”€ updated_at: "2024-01-01T00:00:00"
```

#### **1.3.3 Store Embedding**
```python
def store_product_embedding(self, product_id: str, embedding: np.ndarray, 
                           metadata: Optional[Dict[str, Any]] = None) -> bool:
    # Convert to binary
    vector_bytes = embedding.astype(np.float32).tobytes()
    
    # Store in Redis Hash
    data = {
        'vector': vector_bytes,
        'updated_at': datetime.utcnow().isoformat(),
        **metadata  # category, name, price
    }
    
    self.redis.hset(f"product:embedding:{product_id}", mapping=data)
```

**Quy trÃ¬nh**:
1. Convert numpy array â†’ FLOAT32 â†’ bytes
2. Combine vá»›i metadata
3. Store vÃ o Redis Hash
4. Index tá»± Ä‘á»™ng update (nhá» RedisSearch)

**Metadata Ä‘Æ°á»£c lÆ°u**:
- `category`: Cho filtering
- `name`: Cho display
- `price`: Cho filtering
- `updated_at`: Cho versioning

#### **1.3.4 Similarity Search**
```python
def find_similar_products(self, embedding: np.ndarray, 
                         limit: int = 10, 
                         min_score: float = 0.75) -> List[Dict[str, Any]]:
    query_vector = embedding.astype(np.float32).tobytes()
    
    # RedisSearch KNN Query
    results = self.redis.execute_command(
        "FT.SEARCH", VECTOR_INDEX_NAME,
        f"*=>[KNN {limit} @vector $query_vector AS score]",
        "PARAMS", 2, "query_vector", query_vector,
        "SORTBY", "score",  # Higher score = more similar
        "RETURN", 4, "id", "score", "category", "updated_at"
    )
```

**KNN Query Breakdown**:
- `*=>[KNN {limit} @vector $query_vector AS score]`:
  - `*`: Match all documents
  - `=>[KNN ...]`: K-Nearest Neighbors search
  - `limit`: Top K results
  - `@vector`: Search in vector field
  - `$query_vector`: Parameter binding
  - `AS score`: Similarity score alias

**Káº¿t quáº£ tráº£ vá»**:
```python
[
    {
        'product_id': 'prod-123',
        'similarity_score': 0.89,  # Cosine similarity (0-1)
        'category': 'electronics',
        'embedding_updated_at': '2024-01-01T00:00:00'
    },
    ...
]
```

**Performance**:
- **Time Complexity**: O(log N) vá»›i HNSW
- **Memory**: ~1.5KB per product embedding
- **Typical Latency**: 10-50ms cho 10K products

#### **1.3.5 Get Embedding**
```python
def get_product_embedding(self, product_id: str) -> Optional[np.ndarray]:
    vector_bytes = self.redis.hget(f"product:embedding:{product_id}", 'vector')
    if not vector_bytes:
        return None
    # Convert bytes back to numpy
    vector = np.frombuffer(vector_bytes, dtype=np.float32)
    return vector
```

**Use Cases**:
- Láº¥y embedding Ä‘á»ƒ tÃ­nh similarity trÆ°á»›c khi search
- Validation embeddings
- Migration/debugging

---

## 2. ðŸ“¤ Stream Producer Service (`stream_producer.py`)

### 2.1 Tá»•ng Quan
**Má»¥c Ä‘Ã­ch**: Publish product events vÃ o Redis Streams

**Pattern**: Singleton Pattern
- Shared Redis connection
- Event publishing interface

### 2.2 Kiáº¿n TrÃºc

```
ProductEventProducer (Singleton)
â”œâ”€â”€ Redis Streams Connection
â”œâ”€â”€ publish_product_created()
â”œâ”€â”€ publish_product_updated()
â””â”€â”€ publish_product_deleted()
```

### 2.3 Chi Tiáº¿t Implementation

#### **2.3.1 Initialization**
```python
class ProductEventProducer:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ProductEventProducer, cls).__new__(cls)
            cls._instance.redis = redis.Redis(
                decode_responses=True  # JSON strings
            )
```

**Äáº·c Ä‘iá»ƒm**:
- `decode_responses=True`: Xá»­ lÃ½ JSON strings
- Singleton Ä‘á»ƒ reuse connection
- Lazy initialization

#### **2.3.2 Publish Events**
```python
def publish_product_created(self, product_data: Dict[str, Any]) -> Optional[str]:
    event = {
        'event_type': 'create',
        'timestamp': datetime.utcnow().isoformat(),
        'data': json.dumps(product_data),  # Serialize
        'product_id': product_data['id']
    }
    
    # Add to Redis Stream
    event_id = self.redis.xadd(PRODUCT_STREAM_KEY, event)
    return event_id  # Stream entry ID
```

**Event Structure**:
```json
{
    "event_type": "create|update|delete",
    "product_id": "prod-123",
    "timestamp": "2024-01-01T00:00:00",
    "data": "{'name': '...', 'description': '...', ...}"
}
```

**Redis Stream Entry**:
```
product:updates
â”œâ”€â”€ Entry ID: "1234567890-0" (timestamp-sequence)
â””â”€â”€ Fields: event_type, product_id, timestamp, data
```

#### **2.3.3 Event Types**

**1. Create Event**:
```python
publish_product_created(product_data)
# Full product data in 'data' field
```

**2. Update Event**:
```python
publish_product_updated(product_id, update_data)
# Only changed fields in 'data'
```

**3. Delete Event**:
```python
publish_product_deleted(product_id)
# Only product_id in 'data'
```

**Return Value**:
- `event_id`: Stream entry ID (e.g., "1234567890-0")
- `None`: Náº¿u cÃ³ lá»—i

---

## 3. ðŸ”„ Stream Consumer Service (`stream_consumer.py`)

### 3.1 Tá»•ng Quan
**Má»¥c Ä‘Ã­ch**: Consume events tá»« Redis Streams, generate embeddings, store vectors

**Pattern**: 
- Consumer Group Pattern (Redis Streams)
- Background Thread Processing
- Graceful Shutdown

### 3.2 Kiáº¿n TrÃºc

```
ProductEventConsumer
â”œâ”€â”€ Redis Consumer Group
â”œâ”€â”€ Background Thread
â”œâ”€â”€ Event Processing Loop
â”œâ”€â”€ Embedding Generation
â””â”€â”€ Vector Storage
```

### 3.3 Chi Tiáº¿t Implementation

#### **3.3.1 Initialization**
```python
def __init__(self, consumer_id: Optional[str] = None):
    self.redis = redis.Redis(decode_responses=True)
    self.consumer_id = consumer_id or f"worker-{threading.get_ident()}"
    
    # Dependencies
    self.embedding_model = get_embedding_model()
    self.vector_store = get_vector_store()
    
    # Control flags
    self.running = False
    self.thread = None
    
    # Create consumer group
    self._ensure_consumer_group()
```

**Consumer Group Setup**:
```python
def _ensure_consumer_group(self):
    # Create stream if not exists
    if not self.redis.exists(PRODUCT_STREAM_KEY):
        self.redis.xadd(PRODUCT_STREAM_KEY, {'init': 'true'})
    
    # Create consumer group
    self.redis.xgroup_create(
        PRODUCT_STREAM_KEY,
        PRODUCT_STREAM_GROUP,  # "product-processors"
        id='0',  # Start from beginning
        mkstream=True
    )
```

**Consumer Group Benefits**:
- **Load Balancing**: Multiple consumers chia táº£i
- **Fault Tolerance**: Message reprocessing náº¿u consumer crash
- **At-least-once Delivery**: Äáº£m báº£o xá»­ lÃ½

#### **3.3.2 Start Consumer**
```python
def start(self, batch_size: int = 10, block_ms: int = 2000) -> None:
    if self.running:
        return
    
    self.running = True
    self.thread = threading.Thread(
        target=self._consume_loop,
        args=(batch_size, block_ms),
        daemon=True  # Dies with main process
    )
    self.thread.start()
```

**Parameters**:
- `batch_size=10`: Sá»‘ messages xá»­ lÃ½ má»—i láº§n
- `block_ms=2000`: Thá»i gian block chá» messages (2s)

**Thread Model**:
- **Daemon Thread**: Tá»± Ä‘á»™ng dá»«ng khi main process dá»«ng
- **Non-blocking**: KhÃ´ng block API requests
- **Background Processing**: Async event handling

#### **3.3.3 Consume Loop**
```python
def _consume_loop(self, batch_size: int, block_ms: int) -> None:
    while self.running:
        streams = {PRODUCT_STREAM_KEY: '>'}  # New messages only
        
        messages = self.redis.xreadgroup(
            groupname=PRODUCT_STREAM_GROUP,
            consumername=self.consumer_id,
            streams=streams,
            count=batch_size,
            block=block_ms  # Wait for messages
        )
        
        if not messages:
            continue  # No new messages
        
        # Process messages
        for stream_name, stream_messages in messages:
            for message_id, message_data in stream_messages:
                try:
                    self._process_message(message_id, message_data)
                    # ACK on success
                    self.redis.xack(PRODUCT_STREAM_KEY, 
                                   PRODUCT_STREAM_GROUP, 
                                   message_id)
                except Exception as e:
                    logger.error(f"Error: {e}")
                    # No ACK = will be reprocessed
```

**Consumer Group Read**:
- `'>'`: Äá»c messages má»›i chÆ°a Ä‘Æ°á»£c consumer khÃ¡c claim
- Auto-claim: Consumer claim message khi read
- ACK: Confirm sau khi xá»­ lÃ½ thÃ nh cÃ´ng

**Error Handling**:
- **No ACK**: Message sáº½ Ä‘Æ°á»£c reprocess sau PEL (Pending Entry List) timeout
- **Retry Logic**: Automatic retry qua consumer group
- **Logging**: Log errors Ä‘á»ƒ debug

#### **3.3.4 Process Message**
```python
def _process_message(self, message_id: str, message_data: Dict[str, str]):
    event_type = message_data.get('event_type')
    product_id = message_data.get('product_id')
    data_str = message_data.get('data', '{}')
    
    if event_type == 'create' or event_type == 'update':
        # Parse product data
        product_data = json.loads(data_str)
        if 'id' not in product_data:
            product_data['id'] = product_id
        
        # Generate embedding
        product_embedding = self.embedding_model.get_product_embedding(product_data)
        
        # Prepare metadata
        metadata = {
            'category': product_data.get('category', 'unknown'),
            'name': product_data.get('name', 'unknown'),
            'price': str(product_data.get('price', 0)),
        }
        
        # Store in vector store
        self.vector_store.store_product_embedding(
            product_id=product_id,
            embedding=product_embedding,
            metadata=metadata
        )
        
    elif event_type == 'delete':
        # Delete embedding
        self.vector_store.delete_product_embedding(product_id)
```

**Processing Flow**:
1. **Parse Event**: Extract event_type, product_id, data
2. **Generate Embedding**: 
   - Combine name + description + category
   - TF-IDF vectorization â†’ 384-dim vector
3. **Store Vector**: Save embedding + metadata vÃ o Redis
4. **ACK Message**: Confirm processing success

**Performance Metrics**:
- **Embedding Generation**: ~5-20ms per product
- **Vector Storage**: ~1-5ms per product
- **Total Processing**: ~10-30ms per product

#### **3.3.5 Graceful Shutdown**
```python
def stop(self) -> None:
    if not self.running:
        return
    
    self.running = False
    if self.thread and self.thread.is_alive():
        self.thread.join(timeout=5.0)  # Wait max 5s
```

**Signal Handling**:
```python
def signal_handler(sig, frame):
    consumer.stop()
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)  # Ctrl+C
signal.signal(signal.SIGTERM, signal_handler)  # Kill command
```

---

## 4. ðŸš€ Modern Stream Consumer (`modern_stream_consumer.py`)

### 4.1 Tá»•ng Quan
**Má»¥c Ä‘Ã­ch**: Backend-agnostic consumer sá»­ dá»¥ng adapter pattern

**Pattern**: Adapter Pattern + Event Handler Pattern

**KhÃ¡c biá»‡t vá»›i Stream Consumer**:
- KhÃ´ng phá»¥ thuá»™c Redis trá»±c tiáº¿p
- Há»— trá»£ nhiá»u backend (Redis, Supabase, NATS, ...)
- Code sáº¡ch hÆ¡n, dá»… test hÆ¡n

### 4.2 Kiáº¿n TrÃºc

```
ModernProductEventConsumer
â”œâ”€â”€ EventProcessor (Adapter Interface)
â”‚   â”œâ”€â”€ RedisEventProcessor
â”‚   â”œâ”€â”€ SupabaseEventProcessor
â”‚   â””â”€â”€ NATSEventProcessor (future)
â”œâ”€â”€ VectorStore (Adapter Interface)
â”‚   â”œâ”€â”€ RedisVectorStore
â”‚   â””â”€â”€ PineconeVectorStore
â””â”€â”€ Event Handler
```

### 4.3 Chi Tiáº¿t Implementation

#### **4.3.1 Initialization**
```python
def __init__(self, consumer_id: str = None):
    self.consumer_id = consumer_id or f"modern-worker-{threading.get_ident()}"
    
    # Use adapter factory
    self.event_processor = get_event_processor()  # Interface
    self.vector_store = get_vector_store()  # Interface
    self.embedding_model = get_embedding_model()
    
    # Set event handler
    self.event_processor.set_event_handler(self._handle_event)
```

**Adapter Factory**:
- `get_event_processor()`: Tráº£ vá» adapter dá»±a trÃªn config
- `get_vector_store()`: Tráº£ vá» vector store adapter
- **Flexible**: Dá»… dÃ ng switch backend

#### **4.3.2 Event Handler**
```python
def _handle_event(self, event_data: dict) -> None:
    """Backend-agnostic event handler"""
    event_type = event_data.get('event_type')
    product_id = event_data.get('product_id')
    data = event_data.get('data', {})
    
    if event_type in ['create', 'update']:
        self._process_product_upsert(product_id, data)
    elif event_type == 'delete':
        self._process_product_delete(product_id)
```

**Handler Pattern**:
- Event processor gá»i handler callback
- Handler khÃ´ng biáº¿t backend implementation
- **Decoupled**: Business logic tÃ¡ch khá»i infrastructure

#### **4.3.3 Start/Stop**
```python
def start(self) -> None:
    self.event_processor.start_consumer(self.consumer_id)

def stop(self) -> None:
    self.event_processor.stop_consumer()
```

**Delegation Pattern**:
- Consumer logic Ä‘Æ°á»£c delegate cho adapter
- Má»—i adapter implement theo cÃ¡ch riÃªng
- **Consistent API**: Same interface, different implementations

---

## 5. ðŸ“Š Service Dependencies & Flow

### 5.1 Dependency Graph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Routes     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€> Stream Producer â”€â”€> Redis Streams
         â”‚
         â”œâ”€â”€> Vector Store <â”€â”€â”€ Stream Consumer
         â”‚         â”‚
         â”‚         â”œâ”€â”€> Similarity Search
         â”‚         â”‚
         â”‚         â””â”€â”€> Recommendations
         â”‚
         â””â”€â”€> Embedding Model
```

### 5.2 Complete Flow

#### **Product Creation Flow**:
```
1. POST /products
   â”‚
   â”œâ”€> Store product data (Redis Hash)
   â”‚
   â””â”€> Stream Producer.publish_product_created()
       â”‚
       â””â”€> Redis Streams (product:updates)
           â”‚
           â””â”€> Stream Consumer (background)
               â”‚
               â”œâ”€> Generate Embedding (TF-IDF)
               â”‚
               â””â”€> Vector Store.store_product_embedding()
                   â”‚
                   â””â”€> Redis Vector Index (HNSW)
```

#### **Recommendation Flow**:
```
1. GET /recommendations/{product_id}/similar
   â”‚
   â”œâ”€> Vector Store.get_product_embedding(product_id)
   â”‚
   â”œâ”€> Vector Store.find_similar_products(embedding)
   â”‚   â”‚
   â”‚   â””â”€> RedisSearch KNN Query
   â”‚
   â””â”€> Filter & Rank Results
```

---

## 6. ðŸŽ¯ Design Patterns

### 6.1 Singleton Pattern
- **VectorStore**: Shared Redis connection
- **EventProducer**: Shared Redis connection
- **EmbeddingModel**: Shared model instance

**Benefits**:
- Resource efficiency
- State consistency
- Connection pooling

### 6.2 Adapter Pattern (Modern Consumer)
- **EventProcessorInterface**: Abstract interface
- **RedisEventProcessor**: Redis implementation
- **SupabaseEventProcessor**: Supabase implementation

**Benefits**:
- Backend flexibility
- Easy testing (mock interfaces)
- Code reusability

### 6.3 Consumer Group Pattern
- **Redis Streams**: Consumer groups
- **Load Balancing**: Multiple consumers
- **Fault Tolerance**: Auto-retry

### 6.4 Factory Pattern
- **Adapter Factory**: Create adapters based on config
- **Service Factory**: Create services with dependencies

---

## 7. âš¡ Performance Characteristics

### 7.1 Vector Store
- **Storage**: ~1.5KB per product
- **Search Latency**: 10-50ms (10K products)
- **Scalability**: Linear vá»›i HNSW

### 7.2 Stream Producer
- **Publish Latency**: < 5ms
- **Throughput**: 1000+ events/second
- **Reliability**: At-least-once delivery

### 7.3 Stream Consumer
- **Processing Latency**: 10-30ms per product
- **Throughput**: 50-100 products/second
- **Scalability**: Horizontal (multiple consumers)

### 7.4 Modern Consumer
- **Same Performance**: Adapter pattern khÃ´ng áº£nh hÆ°á»Ÿng
- **Flexibility**: CÃ³ thá»ƒ optimize tá»«ng adapter

---

## 8. ðŸ”§ Configuration

### 8.1 Environment Variables

```python
# Vector Store
VECTOR_STORE_TYPE = "redis"  # or "pinecone"
VECTOR_DIMENSION = 384
VECTOR_INDEX_NAME = "product:vectors"
SIMILARITY_THRESHOLD = 0.75

# Streams
PRODUCT_STREAM_KEY = "product:updates"
PRODUCT_STREAM_GROUP = "product-processors"
PRODUCT_STREAM_CONSUMER = "worker-{}"

# Redis
REDIS_HOST = "localhost"
REDIS_PORT = 6379
REDIS_DB = 0
```

### 8.2 Tuning Parameters

**Consumer Tuning**:
- `batch_size`: TÄƒng Ä‘á»ƒ throughput cao hÆ¡n (nhÆ°ng memory cao hÆ¡n)
- `block_ms`: TÄƒng Ä‘á»ƒ giáº£m CPU (nhÆ°ng latency cao hÆ¡n)

**Vector Store Tuning**:
- `HNSW M`: TÄƒng Ä‘á»ƒ accuracy cao hÆ¡n (nhÆ°ng memory cao hÆ¡n)
- `SIMILARITY_THRESHOLD`: Äiá»u chá»‰nh theo use case

---

## 9. ðŸ› Error Handling

### 9.1 Vector Store
- **Connection Errors**: Retry logic
- **Index Errors**: Auto-create index
- **Storage Errors**: Return False, log error

### 9.2 Stream Producer
- **Publish Errors**: Return None, log error
- **Connection Errors**: Automatic reconnection

### 9.3 Stream Consumer
- **Processing Errors**: No ACK, auto-retry
- **Connection Errors**: Retry loop vá»›i backoff
- **Crash Recovery**: Consumer group reprocessing

---

## 10. ðŸ“ Best Practices

### 10.1 Singleton Services
- âœ… DÃ¹ng singleton cho shared resources
- âœ… Thread-safe initialization
- âœ… Lazy initialization

### 10.2 Error Handling
- âœ… Always log errors
- âœ… Graceful degradation
- âœ… Retry logic vá»›i backoff

### 10.3 Resource Management
- âœ… Close connections properly
- âœ… Graceful shutdown
- âœ… Connection pooling

### 10.4 Monitoring
- âœ… Log processing times
- âœ… Track error rates
- âœ… Monitor consumer lag

---

## 11. ðŸš€ Future Improvements

### 11.1 Performance
- [ ] Batch embedding generation
- [ ] Async vector storage
- [ ] Caching frequently accessed embeddings

### 11.2 Features
- [ ] Dead letter queue cho failed messages
- [ ] Metrics export (Prometheus)
- [ ] Health check endpoints

### 11.3 Scalability
- [ ] Horizontal scaling cho consumers
- [ ] Partitioning streams by category
- [ ] Distributed vector search

---

## Káº¿t Luáº­n

Services layer lÃ  backbone cá»§a há»‡ thá»‘ng:
- **Vector Store**: Fast similarity search
- **Stream Producer**: Reliable event publishing
- **Stream Consumer**: Background processing
- **Modern Consumer**: Flexible backend support

Táº¥t cáº£ Ä‘Æ°á»£c thiáº¿t káº¿ vá»›i:
- **Production-ready**: Error handling, logging, monitoring
- **Scalable**: Horizontal scaling support
- **Maintainable**: Clean code, design patterns
- **Flexible**: Adapter pattern cho multiple backends

